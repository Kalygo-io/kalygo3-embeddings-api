---
title: "DeepSeek AI vs OpenAI Cost Analysis (Feb 2025)"
description: "Transcript for a video on the COMMAND YouTube channel"
url: "https://youtu.be/VjIOt4EtYxk"
publish_date: "2-11-2025"
---

00:00:00.670 [Music]
00:00:03.399 let's now compare the costs of using
00:00:05.000 remotely hosted versions of some of the
00:00:06.680 larger models offered by Deep seek AI
00:00:09.240 with the costs of using open AI we're
00:00:12.240 going to be comparing deep seek R1 aka
00:00:14.839 the largest of the R1 series models from
00:00:16.840 Deep seek AI with open ai's 01 model
00:00:20.240 because 01 is the open AI model that's
00:00:22.119 most similar to deep seek R1 and for
00:00:24.840 shits and giggles even though it's not a
00:00:26.439 part of the R1 series we're also going
00:00:28.599 to be comparing deep seek V 3 with open
00:00:31.080 ai's GPT 40 because GPT 40 is the open
00:00:34.760 AI model that's most similar to deep
00:00:36.360 seek V3 the only prerequisite concept
00:00:39.040 you need to understand to follow along
00:00:40.840 is to know what a token is in this
00:00:43.320 context a token is one building block of
00:00:45.800 a particular ai's vocabulary most of the
00:00:48.920 time a token is going to be a word or a
00:00:51.199 part of a word but to be clear a token
00:00:53.960 represents any common building block of
00:00:56.079 an ai's vocabulary if you're interested
00:00:58.399 in learning more about this token Stu I
00:01:00.280 recommend researching AI tokenizers or
00:01:02.800 bite pair encoding as a starting point
00:01:05.239 in the following cost comparisons you're
00:01:06.880 going to hear the term input tokens
00:01:09.080 which generally speaking means the data
00:01:10.600 that you send to an AI aka the input
00:01:13.240 tokens represent your prompts and you're
00:01:15.759 also going to hear the term output
00:01:17.680 tokens generally speaking output tokens
00:01:20.079 means the data that you receive back
00:01:21.680 from an AI in response to your prompts
00:01:24.720 disclaimer number one at the time of
00:01:26.799 recording I don't seem to be able to
00:01:28.360 purchase credits from the deep seek a AI
00:01:30.240 API platform but I was able to find
00:01:32.880 several american-based deep seek
00:01:34.680 endpoints and I did test them so deep
00:01:36.479 seek does work but for the purposes of
00:01:38.560 these cost comparisons let's just assume
00:01:40.280 that the Deep seek AI API works and that
00:01:42.439 the marketed prices are accurate
00:01:44.479 disclaimer number two all prices shown
00:01:46.759 are a snapshot of what things are like
00:01:48.119 at the time of recording and are subject
00:01:49.759 to change let's go while open ai's 01
00:01:53.640 API charges $15 per 1 million input
00:01:56.719 tokens deep seek AI are1 API charges
00:02:00.240 only 55 cents per 1 million input tokens
00:02:04.240 and while open ai's 01 API charges $60
00:02:07.320 per 1 million output tokens deep seek AI
00:02:10.679 R1 API charges
00:02:12.520 $219 per 1 million output tokens so
00:02:16.319 assuming comparable levels of
00:02:17.680 intelligence as hinted in the research
00:02:19.720 paper this would imply that using deep
00:02:21.959 seek ai's R1 API is approximately 27
00:02:25.000 times cheaper than using open ai's 01
00:02:27.760 API as many people are worried about
00:02:30.160 American National Data security when it
00:02:31.800 comes to the topic of deep seek and
00:02:33.560 rightfully so let's also compare the
00:02:35.680 cost of using deep seek R1 hosted by
00:02:37.599 fireworks AI an american-based company
00:02:40.519 while open AI 01 API charges $15 per 1
00:02:43.640 million input tokens fireworks AIS R1
00:02:46.840 API charges $3 per 1 million input
00:02:49.760 tokens and while open AI 01 API charges
00:02:52.800 $60 per 1 million output tokens
00:02:55.720 fireworks AI R1 API charges $8 per 1
00:02:58.879 million output tokens tokens so assuming
00:03:01.680 comparable levels of intelligence as
00:03:03.319 hinted in the research paper this would
00:03:05.159 imply that using fireworks AI R1 API is
00:03:08.120 five to seven times cheaper than using
00:03:10.080 open ai's 01
00:03:11.799 API remember up till this point all of
00:03:14.560 deep seek ai's models have been open
00:03:16.480 sourced so companies all around the
00:03:18.280 world can run them on their own
00:03:19.959 infrastructure as mentioned for
00:03:21.720 completeness let's also compare the
00:03:23.519 system one style GPT 40 to the system
00:03:27.319 one style deep seek V3 just to get a
00:03:30.480 broader overview of the cost
00:03:31.959 implications presented by Deep seeks
00:03:34.000 arrival on the international AI stage
00:03:36.680 while open AI GPT 40 API charges $2.50
00:03:40.519 per 1 million input tokens deep seek
00:03:43.360 ai's deep seek V3 API charges only 14
00:03:46.560 cents per 1 million input tokens and
00:03:49.560 while open ai's GPT 40 API charges $10
00:03:52.680 per 1 million output tokens deep seek
00:03:55.439 ai's deep seek V3 API charges only 28
00:03:58.599 cents per 1 million output tokens so
00:04:01.760 assuming comparable levels of
00:04:03.000 intelligence using deep seeks deep seek
00:04:05.159 V3 API is 17 to 35 times cheaper than
00:04:08.840 using open AI GPT 40
00:04:11.400 API and finally let's compare the cost
00:04:14.840 of self hosting R1 against using the
00:04:17.918 open AI 01 API this is definitely not
00:04:20.880 going to be applicable to everyone but
00:04:22.280 it's good to know remember because steep
00:04:24.479 seek models are open source you can host
00:04:26.360 them yourself here's an analysis by Alex
00:04:29.120 comfor an ml engineer at near AI that
00:04:31.800 compares the cost of self-hosting R1 on
00:04:34.080 gcp versus using open ai's 01
00:04:37.360 API there are a lot of variables at play
00:04:39.960 here but assuming you rent a beefy
00:04:41.800 machine with 8 gpus from gcp at the rate
00:04:45.320 of $2 per hour for a single hour and are
00:04:49.160 sending and receiving a Non-Stop stream
00:04:51.759 of prompts and
00:04:53.280 responses then the cost of using a
00:04:55.479 self-hosted R1 model is about two times
00:04:58.000 more expensive than using the opena i1
00:05:01.080 API so at the moment compared to using
00:05:04.120 the open ai1 API from a cost savings
00:05:07.360 perspective self-hosting R1 really only
00:05:10.840 makes sense if you have a use case where
00:05:12.320 you're constantly calling the model with
00:05:14.600 almost no
00:05:15.639 pauses and if you can acquire some
00:05:18.400 machines from some cloud provider like
00:05:20.039 for example gcp or AWS at a rate of
00:05:23.680 under $10 per hour per
00:05:27.560 machine the other scenario I can think
00:05:29.479 of regarding self-hosting R1 is if you
00:05:31.360 own your gpus if you own your gpus or
00:05:34.759 your machine your Hardware Etc that
00:05:36.360 you're using to run these models if you
00:05:37.960 own those machines and the costs of
00:05:40.360 running them are under $10 per hour per
00:05:43.600 machine then yes you eventually will
00:05:46.479 recoup the Investments that you made
00:05:48.120 into acquiring those
00:05:50.080 machines hopefully that makes sense if I
00:05:52.720 said anything inaccurate leave a comment
00:05:55.639 so in conclusion the latest batch of
00:05:57.680 models from Deep seek AI are definitely
00:05:59.400 something to pay attention to over the
00:06:00.880 course of 2025 but my general assessment
00:06:03.680 is that collectively we have to test
00:06:05.000 them a lot more to see how good they
00:06:06.560 really are if you have data concerns in
00:06:09.360 respect to American National Security
00:06:11.080 rightfully so I recommend using a
00:06:13.280 self-hosted or American hosted version
00:06:15.240 of whatever deep seek AI model you're
00:06:16.840 most interested in here are some
00:06:19.000 us-based AI hosting providers you can
00:06:21.280 check out to start with if you're using
00:06:23.840 deep seek in production leave a comment
00:06:25.840 letting us know your experience and sha
00:06:28.840 to Jin
00:06:30.080 I think that means see you next time in
00:06:32.000 Mandarin peace
